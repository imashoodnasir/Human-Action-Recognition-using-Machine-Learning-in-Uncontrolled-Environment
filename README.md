<h1>Human Action Recognition using Machine Learning in Uncontrolled Environment</h1>

<p>In this article, an efficient technique to classify human actions by utilizing steps like removing redundant frames from videos, extracting Segments of Interest (SoIs), feature descriptor mining through Geodesic Distance (GD), 3D Cartesian-plane Features (3D-CF), Joints MOCAP (JMOCAP) and n-way Point Trajectory Generation (nPTG).</p>
<p>A Neuro Fuzzy Classifier (NFC) is used at the end for the classification purpose</p>
<p>The proposed technique is tested on two publicly available datasets including HMDB-51 and Hollywood2, and achieved an accuracy of 82.55% and 91.99% respectively. These efficient results prove the validity of proposed model.</p>


<h3>Structure of proposed HAR model</h3>
<img src="https://user-images.githubusercontent.com/122672521/217169526-53e6d55e-9df7-4225-b700-26e11bc30c7a.jpg" alt="Structure of proposed HAR model">



<h3>Citation</h3>
<h3>Nasir, Inzamam Mashood, et al. "Human action recognition using machine learning in uncontrolled environment." 2021 1st International Conference on Artificial Intelligence and Data Analytics (CAIDA). IEEE, 2021.</h3>
